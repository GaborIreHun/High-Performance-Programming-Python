{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPP_CA_PART_B.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 01 Multiply 2D Matrice on the GPU"
      ],
      "metadata": {
        "id": "YwsJR71ZtuVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell A"
      ],
      "metadata": {
        "id": "IgUxKO03t_9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda, types\n",
        "\n",
        "@cuda.jit\n",
        "def mm(a, b, c):\n",
        "    \n",
        "    row, column = cuda.grid(2)\n",
        "    sum = 0\n",
        "\n",
        "    # Checking if row and column are within valid c boundary\n",
        "    if row < c.shape[0] and column < c.shape[1]:\n",
        "        \n",
        "        # Computing partial products\n",
        "        for k in range(a.shape[1]):\n",
        "            sum += a[row, k] * b[k, column]\n",
        "        # Defining the product of a and b\n",
        "        c[row, column] = sum"
      ],
      "metadata": {
        "id": "PGZbs6sDjrBA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(numba.pydata.org, n.d.)"
      ],
      "metadata": {
        "id": "gqsCbiZ5piNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps taken:\n",
        "\n",
        "- The first step was to prevent the row and column to be out of the boundary of the output matrix(c)\n",
        "- As both matrices have the same shape, we could calculate the partial product iterating through the shape of a. The sum was incremented with the value of the partial products at each iteration.\n",
        "- The value of sum was assigned to c."
      ],
      "metadata": {
        "id": "At1B50Is5Py1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell B (Pre-defined)"
      ],
      "metadata": {
        "id": "AqOrA2PMuf39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(16).reshape(4,4).astype(np.int32)\n",
        "b = np.arange(16).reshape(4,4).astype(np.int32)\n",
        "c = np.zeros_like(a)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_b = cuda.to_device(b)\n",
        "d_c = cuda.to_device(c)\n",
        "\n",
        "grid = (2,2)\n",
        "block = (2,2)\n",
        "mm[grid, block](d_a, d_b, d_c)"
      ],
      "metadata": {
        "id": "NZnUt6y_ueg_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell C (Pre-defined)"
      ],
      "metadata": {
        "id": "EN2-eb79vLVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import testing\n",
        "solution = a@b\n",
        "output = d_c.copy_to_host()\n",
        "\n",
        "testing.assert_array_equal(output, solution)"
      ],
      "metadata": {
        "id": "c6Pj7a07vNG8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ILQizm4I-lC",
        "outputId": "c47b951b-8f20-4c19-880a-7a6e249d9036"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 56  62  68  74]\n",
            " [152 174 196 218]\n",
            " [248 286 324 362]\n",
            " [344 398 452 506]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02 Add 2D Matrices Larger than the Grid Size"
      ],
      "metadata": {
        "id": "8rt4SV4HI968"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell A"
      ],
      "metadata": {
        "id": "t9WIlFJ7I42j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def add_matrix_stride(A,B,C):\n",
        "  # Unique thread index within the entire grid\n",
        "  start = cuda.grid(1)\n",
        "  # The total number of threads in the entire grid\n",
        "  stride = cuda.gridsize(1)\n",
        "\n",
        "  # Calculating sum for all elements\n",
        "  for a in range(start, A.shape[0], stride):\n",
        "      C[a] = A[a] + B[a]"
      ],
      "metadata": {
        "id": "gRgjlzXdhQLG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell B (no modification needed)"
      ],
      "metadata": {
        "id": "8TPhnYiGJ0yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.arange(64*64).reshape(64*64).astype(np.int32)\n",
        "B = A * 2\n",
        "C = np.zeros_like(A)\n",
        "\n",
        "d_A = cuda.to_device(A)\n",
        "d_B = cuda.to_device(B)\n",
        "d_C = cuda.to_device(C)\n",
        "\n",
        "blocks = (6,6)\n",
        "threads_per_block = (6,6)\n",
        "\n",
        "add_matrix_stride[blocks, threads_per_block](d_A, d_B, d_C)"
      ],
      "metadata": {
        "id": "QQnJVP2XJ6dU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell C (for testing purposes only)"
      ],
      "metadata": {
        "id": "Ny0db0xbLKNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = d_C.copy_to_host()\n",
        "solution = A+B\n",
        "\n",
        "testing.assert_array_equal(output, solution)"
      ],
      "metadata": {
        "id": "YPoK9JkSLEoR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps taken:\n",
        "\n",
        "Although this task did not require lots of code, however probably due to some over complication I done great amount of research, however at the end I sticked to a very basic solution.\n",
        "- The first two added lines were the cuda provided variables for calculating the unique thread indexes and the number of threads within the entire grid.\n",
        "- The threads then will start to work through the data elements from the appropriate indexes until the data's boundaries with each iteration. "
      ],
      "metadata": {
        "id": "D90xELB8qlXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. Matrix Transposition using Shared Memory"
      ],
      "metadata": {
        "id": "RU6sAWPwlaLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell A (Matrix Transposition without Shared Memory)"
      ],
      "metadata": {
        "id": "Rp4hHVlp35dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def transpose(a_in, a_out):\n",
        "  row = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "  col = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "\n",
        "  a_out[row, col] = a_in[col, row]"
      ],
      "metadata": {
        "id": "ZNkMY02_ligT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell B (Matrix Transposition with Shared Memory)"
      ],
      "metadata": {
        "id": "Kdx8RDm64HQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numba.types\n",
        "\n",
        "@cuda.jit\n",
        "def transpose_shared(a_in, a_out):\n",
        "  # The block dimension is assumed (Tile size*Tile size - current task 32*32)\n",
        "  # and also the multiple tile sized input.\n",
        "  # At the assumed block dimension a padded size of tile dimension also has\n",
        "  # been utilized.\n",
        "  tile = cuda.shared.array((32, 33), numba.types.int32)\n",
        "\n",
        "  # Thread a box indexing pattern using the tile dimension as stride\n",
        "  x = cuda.blockIdx.x * 32 + cuda.threadIdx.x\n",
        "  y = cuda.blockIdx.y * 32 + cuda.threadIdx.y\n",
        "  \n",
        "  # Transpose tile into shared memory\n",
        "  for j in range(0, 32, 32):\n",
        "      tile[cuda.threadIdx.y + j, cuda.threadIdx.x] = a_in[y + j, x] \n",
        "\n",
        "  # Wait for all threads in the block to finish updating shared memory\n",
        "  cuda.syncthreads()  \n",
        "\n",
        "  # Compute transposed offsets\n",
        "  x = cuda.blockIdx.y * 32 + cuda.threadIdx.x\n",
        "  y = cuda.blockIdx.x * 32 + cuda.threadIdx.y\n",
        "\n",
        "  for j in range(0, 32, 32):\n",
        "      a_out[y + j, x] = tile[cuda.threadIdx.x, cuda.threadIdx.y + j];\n",
        "\n",
        "# Credits to Mark Harris"
      ],
      "metadata": {
        "id": "DmuVhTnJpYIh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Mark, 2013)"
      ],
      "metadata": {
        "id": "jA_kbfn7rkYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps taken:\n",
        "\n",
        "- A shared array was created (tile) with the assumed block dimension of 32x32. Also, the input is assumed here to be multiplication of the tile. The padded tile size was also utilized to define the block dimension what was the tile size plus one (32 + 1). Therefore, the shape of the given shared memory bank size was slanted, however this is to prevent bank conflict (Mark, 2013).\n",
        "- The box indexing pattern was threaded by using the tile dimension as stride.\n",
        "- The tile was transposed (copied) into the shared memory with the aid of a for loop.\n",
        "- The threads were syncronized then by utilizing syncthreads(), so all threads in the block could finish updating the shared memory.\n",
        "- The copied offsets then were computed.\n",
        "- Finally, the data was transferred back from shared memory."
      ],
      "metadata": {
        "id": "P4OpOcuH6MW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell C (Pre-defined)"
      ],
      "metadata": {
        "id": "kr45FJSl4TEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = 16384\n",
        "a_in = cuda.to_device(np.arange(size*size, dtype=np.int32).reshape((size, size)))\n",
        "a_out = cuda.device_array_like(a_in)\n",
        "\n",
        "print(a_in.copy_to_host())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0JnJPu7nC5v",
        "outputId": "54546839-03c8-44cd-d84b-ba8de10dc78d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[        0         1         2 ...     16381     16382     16383]\n",
            " [    16384     16385     16386 ...     32765     32766     32767]\n",
            " [    32768     32769     32770 ...     49149     49150     49151]\n",
            " ...\n",
            " [268386304 268386305 268386306 ... 268402685 268402686 268402687]\n",
            " [268402688 268402689 268402690 ... 268419069 268419070 268419071]\n",
            " [268419072 268419073 268419074 ... 268435453 268435454 268435455]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell D (Pre-defined)"
      ],
      "metadata": {
        "id": "9dH5WFD74a_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threads_per_block = (32, 32)\n",
        "blocks_per_grid = (int(size/threads_per_block[0]), int(size/threads_per_block[1]))"
      ],
      "metadata": {
        "id": "7lEF7uK9npfK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell E (Pre-defined)"
      ],
      "metadata": {
        "id": "hy-8n-hw4iEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba.cuda.api import synchronize\n",
        "%timeit transpose[blocks_per_grid, threads_per_block](a_in, a_out); cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0MPXOqUoEYr",
        "outputId": "a96e5ff6-34a1-4f66-cec3-27f6a610c1cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 7.22 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10 loops, best of 5: 26.1 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell F (Pre-defined)"
      ],
      "metadata": {
        "id": "RzslHi8l4lRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit transpose_shared[blocks_per_grid, threads_per_block](a_in, a_out); cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi01Jbdzq5wW",
        "outputId": "e8a22aca-bc20-4b57-9ca5-8d69f691354a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 45.72 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 11.2 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell G (Pre-defined)"
      ],
      "metadata": {
        "id": "NfV1xAj24ork"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a_out.copy_to_host())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ut4M5qwocy9",
        "outputId": "adc79d87-bbbc-42eb-80a8-a95351582009"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[        0     16384     32768 ... 268386304 268402688 268419072]\n",
            " [        1     16385     32769 ... 268386305 268402689 268419073]\n",
            " [        2     16386     32770 ... 268386306 268402690 268419074]\n",
            " ...\n",
            " [    16381     32765     49149 ... 268402685 268419069 268435453]\n",
            " [    16382     32766     49150 ... 268402686 268419070 268435454]\n",
            " [    16383     32767     49151 ... 268402687 268419071 268435455]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "- Mark, H. (2013). An Efficient Matrix Transpose in CUDA C/C++ | NVIDIA Technical Blog. [online] Available at: https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/\n",
        "- numba.pydata.org. (n.d.). Examples â€” Numba 0.52.0.dev0+274.g626b40e-py3.7-linux-x86_64.egg documentation. [online] Available at: https://numba.pydata.org/numba-doc/dev/cuda/examples.html"
      ],
      "metadata": {
        "id": "u998wikKzhUj"
      }
    }
  ]
}